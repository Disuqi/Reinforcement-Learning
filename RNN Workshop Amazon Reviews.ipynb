{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c09cf8d",
   "metadata": {},
   "source": [
    "# Workshop on Recurrent networks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0500f5f",
   "metadata": {},
   "source": [
    "## 1. Define some constants and some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d32e9ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_reviews = 21967    # no of reviews that will be read from file. \n",
    "max_review_length = 100 # no of words per review.  reviews will be  truncated or padded to be of this length.\n",
    "max_words = 5000        # this is the size of the index (i.e. most common top words that will be used as features)\n",
    "                        # note code assumes there are enough words in reviews.\n",
    "embedding_dim = 100     # length of embedding based on Glove\n",
    "validation_prop = 0.2   # prop of data for validation set\n",
    "no_epochs =   10         # No of training cycles for the networks\n",
    "batch_size = 128        # batch size for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65a3e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cd8bbf",
   "metadata": {},
   "source": [
    "## 2. Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8074f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def read_data(file_path, no_reviews):\n",
    "    # Split the data into input (review text) and output (rating)\n",
    "    reviews = []\n",
    "    ratings = []\n",
    "    with open(file_path, mode='r', newline='', encoding='utf-8') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        next(csv_reader)  # Skip the header row if it exists\n",
    "        for row in csv_reader:\n",
    "            # Assuming stars is at index 3 and review_body is at index 5\n",
    "            ratings.append(row[3])\n",
    "            reviews.append(row[5])\n",
    "\n",
    "    return reviews, ratings\n",
    "                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b363f5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 21966 lines from ./reviews_for_classification.csv\n",
      "0 Rating: 5: The best in all that matters! It's a great platform, easy and simple to use, and beginner-friendly. The only one in crypto that offers you to actually call a phone number and get to someone with your questions just like that. Highly recommend! I have been a customer for more than a year and I have only good things to say about Celsius network.\n",
      "1 Rating: 5: If you are looking for the best #HomeForCrypto and where to earn steady yield then there is no better place than Celsius Network. The app is easy to use and understand with a recent update as well. The company is led by a great CEO who is fully engaged with the Celsius community! The mission of Celsius is to do good then do well and they live up to that very much. Rewards compound and pay out weekly!\n",
      "2 Rating: 1: I despise it so much. Transferring to other wallets is difficult, especially because you cannot swap your coins, and there is a long waiting period when you do send to someone. Verification within 24 hours. When compared to Crypto.com, I find it extremely difficult to gain access to your funds. I'm never going to use it again. My biggest blunder!\n",
      "3 Rating: 1: Worst customer service and worst company to deal with donâ€™t waste your time depositing your coins in there. You will get a run around. I am trying to withdraw coins from their platforms to another wallet and this been going on for over a month. Every time I call everyone is clueless and also they said that another country is in charge of the withdraw is all BS BE AWARE DONT WASTE YOUR TIME\n",
      "4 Rating: 5: Celsius is the most transparent and responsive company I've seen in the crypto space. I have never experienced any issues using their products, and they have consistently paid higher rates on crypto than other yield platforms. It is my first recommendation to crypto newbies and veterans alike. You will try it once and never want to leave!\n",
      "5 Rating: 5: Best wallet to manage, store and get rewards with my crypto. Using the app since 2019, Celsius never miss weekly rewards deposited to my wallet. Best place to buy and swap between different crypto asses all this services and more with zero fees. Just go and try it.Leo\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./reviews_for_classification.csv\"\n",
    "\n",
    "reviews, ratings = read_data(file_path, no_reviews)\n",
    "\n",
    "print(f\"Read in {len(ratings)} lines from {file_path}\")\n",
    "      \n",
    "for i in range(6):\n",
    "    print(f\"{i} Rating: {ratings[i]}: {reviews[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d8065a",
   "metadata": {},
   "source": [
    "## 3. Pre-process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "431bdfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15368 unique tokens\n",
      "Line 1: If you are looking for the best #HomeForCrypto and where to earn steady yield then there is no better place than Celsius Network. The app is easy to use and understand with a recent update as well. The company is led by a great CEO who is fully engaged with the Celsius community! The mission of Celsius is to do good then do well and they live up to that very much. Rewards compound and pay out weekly!\n",
      "\n",
      "Coded :  [52, 16, 35, 407, 10, 3, 105, 4, 225, 2, 461, 3047, 776, 84, 72, 8, 27, 192, 405, 103, 159, 520, 3, 64, 8, 33, 2, 46, 4, 311, 12, 5, 1134, 624, 47, 172, 3, 82, 8, 2475, 97, 5, 44, 859, 158, 8, 1337, 4353, 12, 3, 159, 667, 3, 3048, 11, 159, 8, 2, 45, 76, 84, 45, 172, 4, 7, 451, 57, 2, 15, 40, 165, 366, 3049, 4, 116, 59, 680]\n"
     ]
    }
   ],
   "source": [
    "# Use the tokenizer to code the reviews\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(f'Found {len(word_index)} unique tokens')\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(reviews)\n",
    "\n",
    "print(\"Line 1:\",reviews[1])\n",
    "print(\"\\nCoded : \", sequences[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d886cb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data = (21966, 100)\n",
      "Shape of Labels = (21966,)\n"
     ]
    }
   ],
   "source": [
    "data = pad_sequences(sequences, maxlen= max_review_length)\n",
    "\n",
    "ratings = np.asarray(ratings)\n",
    "print('Shape of Data =', data.shape)\n",
    "print('Shape of Labels =', ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af1dbc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of validation set = 4393\n",
      "Length of training set = 17573\n"
     ]
    }
   ],
   "source": [
    "len_val = int(len(data) * validation_prop)\n",
    "\n",
    "x_val = data[:len_val]\n",
    "partial_x_train = data[len_val:]\n",
    "\n",
    "y_val = ratings[:len_val]\n",
    "partial_y_train = ratings[len_val:]\n",
    "\n",
    "print('Length of validation set =', len(x_val))\n",
    "print('Length of training set =', len(partial_x_train))\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ac036",
   "metadata": {},
   "source": [
    "## 4. Load the Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cde57837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of words in glove embeddings = 400000\n"
     ]
    }
   ],
   "source": [
    "glove_dir = './Glove 6B'\n",
    "\n",
    "embeddings_index = {}\n",
    "\n",
    "f = open(os.path.join(glove_dir,'glove.6B.100d.txt'),encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype = 'float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('no of words in glove embeddings =', len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46cb1cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of embeddings matrix is: (5000, 100)\n",
      "1:i\t--> [-0.046539    0.61966002  0.56647003 -0.46584001 -1.18900001  0.44599   ]\n",
      "2:to\t--> [-0.18970001  0.050024    0.19084001 -0.049184   -0.089737    0.21006   ]\n",
      "3:the\t--> [-0.038194   -0.24487001  0.72812003 -0.39961001  0.083172    0.043953  ]\n",
      "4:and\t--> [-0.071953    0.23127     0.023731   -0.50638002  0.33923     0.19589999]\n",
      "5:a\t--> [-0.27085999  0.044006   -0.02026    -0.17395     0.6444      0.71213001]\n",
      "6:my\t--> [ 0.080273   -0.10861     0.72066998 -0.45135999 -0.74959999  0.63782001]\n",
      "7:they\t--> [-0.07954     0.30171001  0.079516   -0.74662    -0.67878997  0.35029   ]\n",
      "8:is\t--> [-0.54263997  0.41475999  1.03219998 -0.40244001  0.46691     0.21816   ]\n",
      "9:it\t--> [-0.30664     0.16821     0.98510998 -0.33605999 -0.24160001  0.16186   ]\n",
      "10:for\t--> [-0.14401001  0.32554001  0.14257    -0.099227    0.72535998  0.19321001]\n"
     ]
    }
   ],
   "source": [
    "#look for word embeddings\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "\n",
    "for word,i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "\n",
    "print(\"shape of embeddings matrix is:\",  embedding_matrix.shape)\n",
    "\n",
    "# print some entries\n",
    "    \n",
    "for word,i in word_index.items():\n",
    "    if i > 10: break \n",
    "    print(f'{i}:{word}\\t--> { embedding_matrix[i, 0:6]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c065c987",
   "metadata": {},
   "source": [
    "## 5. Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49204a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 100)\n",
      "5000\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape)\n",
    "print(max_words)\n",
    "print(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec6c3541",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You called `set_weights(weights)` on layer 'embedding' with a weight list of length 1, but the layer was expecting 0 weights.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43membedding_matrix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/layer.py:666\u001b[0m, in \u001b[0;36mLayer.set_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    664\u001b[0m layer_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer_weights) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(weights):\n\u001b[0;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    667\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou called `set_weights(weights)` on layer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith a weight list of length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(weights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    669\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwas expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(layer_weights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    670\u001b[0m     )\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(layer_weights, weights):\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m variable\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m value\u001b[38;5;241m.\u001b[39mshape:\n",
      "\u001b[0;31mValueError\u001b[0m: You called `set_weights(weights)` on layer 'embedding' with a weight list of length 1, but the layer was expecting 0 weights."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8a70ab",
   "metadata": {},
   "source": [
    "##  6. Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c29d59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
